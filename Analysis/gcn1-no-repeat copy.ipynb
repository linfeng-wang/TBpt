{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f71dd81ed30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% env: new-ml\n",
    "\n",
    "from array import array\n",
    "from cmath import nan\n",
    "from pyexpat import model\n",
    "import statistics\n",
    "from tkinter.ttk import Separator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import variable\n",
    "from itertools import chain\n",
    "from sklearn import metrics as met\n",
    "import pickle\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from importlib import reload\n",
    "# import util\n",
    "# import model_torch_simple\n",
    "# from torchmetrics import Accuracy\n",
    "from tqdm import tqdm   \n",
    "import argparse\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#%%\n",
    "seed = 42\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# train_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_train_gene.csv', delimiter = ',')\n",
    "# train_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_train_hml.csv')\n",
    "# train_target = train_target[['EMB_MIC']]\n",
    "# # don't touch test data, split out validation data from training data during training\n",
    "# # test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_EMB/aa_data_test_pca4k.csv', delimiter = ',')\n",
    "# test_data = np.loadtxt('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/aa_data_test_gene.csv', delimiter = ',')\n",
    "# test_target = pd.read_csv('/mnt/storageG1/lwang/Projects/tb_dr_MIC_v2/data_new_emb/mic_aa_test_hml.csv')\n",
    "# test_target = test_target[['EMB_MIC']]\n",
    "\n",
    "# all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "# all_target = pd.concat((train_target, test_target), axis=0)\n",
    "\n",
    "# train_data, test_data, train_target, test_target = train_test_split(all_data, all_target, test_size=0.2, random_state=42, stratify=all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "    \n",
    "def value_counts_list(lst):\n",
    "    \"\"\"\n",
    "    Computes the frequency count of unique elements in a list and returns a dictionary, sorted by frequency count in\n",
    "    descending order.\n",
    "\n",
    "    Args:\n",
    "    - lst (list): List of elements\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with unique elements as keys and their frequency count as values, sorted by frequency count\n",
    "      in descending order\n",
    "    \"\"\"\n",
    "    value_counts = {}\n",
    "    for item in lst:\n",
    "        if item in value_counts:\n",
    "            value_counts[item] += 1\n",
    "        else:\n",
    "            value_counts[item] = 1\n",
    "    sorted_value_counts = dict(sorted(value_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13016/398589087.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  clinical_lung['country'] = clinical_lung['country'].replace(country_mapping).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "clinical_lung = pd.read_csv('/mnt/storageG1/lwang/Projects/TBpt/Analysis/clinical_lung17102024.csv')\n",
    "clinical_lung.drop(columns=['condition_id'], inplace=True)\n",
    "\n",
    "country_mapping = {\n",
    "    'China': 1,        # High medical capacity, large infrastructure, advanced technology\n",
    "    'India': 2,        # Large infrastructure, but strained capacity due to population\n",
    "    'South Africa': 3, # Developed healthcare, but regional disparities\n",
    "    'Romania': 4,      # Developing EU healthcare standards\n",
    "    'Ukraine': 5,      # Moderate capacity but strained due to recent conflicts\n",
    "    'Belarus': 6,      # Moderate capacity, state-funded healthcare\n",
    "    'Kazakhstan': 7,   # Developing healthcare system\n",
    "    'Azerbaijan': 8,   # Developing healthcare system\n",
    "    'Georgia': 9,      # Smaller healthcare capacity, improving\n",
    "    'Moldova': 10,     # Limited resources, developing healthcare\n",
    "    'Kyrgyzstan': 11,  # Limited resources, developing healthcare\n",
    "    'Nigeria': 12,     # Limited healthcare capacity, large population challenges\n",
    "    'Senegal': 13      # Developing healthcare system with limited resources\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'country' column\n",
    "clinical_lung['country'] = clinical_lung['country'].replace(country_mapping).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_lung_features = clinical_lung[[ 'overall_percent_of_abnormal_volume',\n",
    "       'pleural_effusion_percent_of_hemithorax_involved',\n",
    "       'ispleuraleffusionbilateral', 'other_non_tb_abnormalities',\n",
    "       'are_mediastinal_lymphnodes_present', 'collapse', 'smallcavities',\n",
    "       'mediumcavities', 'largecavities',\n",
    "       'isanylargecavitybelongtoamultisextantcavity',\n",
    "       'canmultiplecavitiesbeseen', 'infiltrate_lowgroundglassdensity',\n",
    "       'infiltrate_mediumdensity', 'infiltrate_highdensity', 'smallnodules',\n",
    "       'mediumnodules', 'largenodules', 'hugenodules',\n",
    "       'isanycalcifiedorpartiallycalcifiednoduleexist',\n",
    "       'isanynoncalcifiednoduleexist', 'isanyclusterednoduleexists',\n",
    "       'aremultiplenoduleexists', 'lowgroundglassdensityactivefreshnodules',\n",
    "       'mediumdensitystabalizedfibroticnodules',\n",
    "       'highdensitycalcifiedtypicallysequella', 'timika_score',\n",
    "       'education', 'gender', 'employment', 'type_of_resistance',\n",
    "       'number_of_daily_contacts', 'bmi', 'lung_localization', 'totalcavernum',\n",
    "       'case_definition', 'diagnosis_code', 'comorbidity',\n",
    "       'social_risk_factors']]#'condition_id','country'\n",
    "\n",
    "clinical_lung_labels = clinical_lung[['outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,  ..., 10149, 10149, 10149],\n",
      "        [ 1591,  2236,  5701,  ...,  1811,  5927,  6150]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "\n",
    "# Example data: each row is a sample, each column is a feature\n",
    "\n",
    "# Generate a k-nearest neighbors graph, specifying the number of neighbors\n",
    "n_neighbors = 5\n",
    "knn_graph = kneighbors_graph(clinical_lung_features, n_neighbors=n_neighbors, mode='connectivity', include_self=False)\n",
    "\n",
    "# Convert the sparse matrix to dense format if needed\n",
    "dense_matrix = knn_graph.toarray()\n",
    "\n",
    "row_indices, col_indices = np.nonzero(dense_matrix)\n",
    "\n",
    "# Stack these indices to create an edge index (2 x num_edges)\n",
    "edge_index = np.stack([row_indices, col_indices], axis=0)\n",
    "\n",
    "# Convert edge_index to a PyTorch tensor (if you're using PyTorch Geometric)\n",
    "edge_index_tensor = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "# Now edge_index_tensor is in the format that a GCN can use: (2 x num_edges)\n",
    "print(edge_index_tensor)\n",
    "# Check the unique values in the generated matrix\n",
    "# unique_values = np.unique(dense_matrix)\n",
    "# print(\"Unique values:\", unique_values)\n",
    "adjacency_matrix = dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Assume clinical_lung_features is your input DataFrame and clinical_lung_labels is your labels Series\n",
    "# clinical_lung_features: DataFrame of shape (10150, 38)\n",
    "# clinical_lung_labels: Series of shape (10150,)\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "features = clinical_lung_features.values  # shape (10150, 38)\n",
    "labels = clinical_lung_labels.values      # shape (10150,)\n",
    "\n",
    "# Parameters\n",
    "n_neighbors = 5  # Number of neighbors for KNN graph\n",
    "\n",
    "# Step 1: Perform stratified split into train+val and test sets\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    np.arange(features.shape[0]),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Step 2: Further split the train+val set into training and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices,\n",
    "    test_size=0.25,  # 0.25 * 0.8 = 0.2 of the total data\n",
    "    random_state=42,\n",
    "    stratify=labels[train_val_indices]\n",
    ")\n",
    "\n",
    "# Function to remove duplicates and create adjacency matrix\n",
    "def prepare_dataset(indices, features, labels, n_neighbors):\n",
    "    # Extract subset features and labels\n",
    "    subset_features = features[indices]\n",
    "    subset_labels = labels[indices]\n",
    "\n",
    "    # Combine features and labels into a DataFrame to remove duplicates\n",
    "    subset_data = pd.DataFrame(subset_features)\n",
    "    subset_data['label'] = subset_labels\n",
    "\n",
    "    # Remove duplicates\n",
    "    subset_data = subset_data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Separate features and labels after removing duplicates\n",
    "    subset_features = subset_data.iloc[:, :-1].values\n",
    "    subset_labels = subset_data['label'].values\n",
    "\n",
    "    # Create adjacency matrix using KNN graph\n",
    "    knn_graph = kneighbors_graph(subset_features, n_neighbors=n_neighbors, mode='connectivity', include_self=False)\n",
    "    # Get edge indices\n",
    "    row_indices, col_indices = knn_graph.nonzero()\n",
    "    edge_index = np.stack([row_indices, col_indices], axis=0)\n",
    "    edge_index_tensor = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "    # Convert features and labels to tensors\n",
    "    features_tensor = torch.tensor(subset_features, dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(subset_labels, dtype=torch.long)\n",
    "\n",
    "    return features_tensor, labels_tensor, edge_index_tensor\n",
    "\n",
    "# Prepare training dataset\n",
    "train_features_tensor, train_labels_tensor, train_edge_index_tensor = prepare_dataset(\n",
    "    train_indices, features, labels, n_neighbors\n",
    ")\n",
    "\n",
    "# Prepare validation dataset\n",
    "val_features_tensor, val_labels_tensor, val_edge_index_tensor = prepare_dataset(\n",
    "    val_indices, features, labels, n_neighbors\n",
    ")\n",
    "\n",
    "# Prepare test dataset\n",
    "test_features_tensor, test_labels_tensor, test_edge_index_tensor = prepare_dataset(\n",
    "    test_indices, features, labels, n_neighbors\n",
    ")\n",
    "\n",
    "# Create PyTorch Geometric Data objects\n",
    "train_data = Data(x=train_features_tensor, edge_index=train_edge_index_tensor, y=train_labels_tensor)\n",
    "val_data = Data(x=val_features_tensor, edge_index=val_edge_index_tensor, y=val_labels_tensor)\n",
    "test_data = Data(x=test_features_tensor, edge_index=test_edge_index_tensor, y=test_labels_tensor)\n",
    "\n",
    "    \n",
    "# Now you can proceed to create DataLoaders and define your GCN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 2: Create the edge_index for both training and testing\n",
    "# # You could keep the same adjacency matrix for both if the graph structure is the same.\n",
    "# def adjacency_to_edge_index(adj_matrix):\n",
    "#     edge_index = np.array(np.nonzero(adj_matrix))  # Get the non-zero indices of the adjacency matrix\n",
    "#     return torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "# edge_index = adjacency_to_edge_index(adjacency_matrix)\n",
    "# edge_index_train = adjacency_to_edge_index(train_adj_matrix)\n",
    "# edge_index_val = adjacency_to_edge_index(val_adj_matrix )\n",
    "# edge_index_test = adjacency_to_edge_index(test_adj_matrix)\n",
    "\n",
    "# # Step 3: Create PyTorch Geometric Data objects if you're using graph data\n",
    "# train_data = Data(x=train_features, edge_index=torch.tensor(edge_index_train), y=train_labels)\n",
    "# val_data = Data(x=val_features, edge_index=torch.tensor(edge_index_val), y=val_labels)\n",
    "# test_data = Data(x=test_features, edge_index=torch.tensor(edge_index_test), y=test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_tensor = train_labels_tensor.flatten()\n",
    "# Convert the flattened tensor to a DataFrame\n",
    "_ = pd.DataFrame(flattened_tensor.numpy(), columns=['a'])\n",
    "\n",
    "y_true = _\n",
    "# y_true = pd.concat([train_target, test_target])\n",
    "\n",
    "column_weight_maps = {}\n",
    "\n",
    "for column in y_true.columns:\n",
    "    column_values = y_true[column].dropna().values\n",
    "    values, counts = np.unique(column_values, return_counts=True)\n",
    "    frequency = counts / len(column_values)\n",
    "    \n",
    "    # Calculate weights as the inverse of frequencies\n",
    "    weights_inverse = 1/frequency\n",
    "    # weights_inverse = 1 - frequency\n",
    "    \n",
    "    # Normalize weights to ensure they sum up to 1\n",
    "    weights_normalized = weights_inverse / np.sum(weights_inverse)\n",
    "    \n",
    "    # Map each MIC value to its corresponding weight\n",
    "    weight_map = {value: weight for value, weight in zip(values, weights_normalized)}\n",
    "    \n",
    "    column_weight_maps[column] = weight_map\n",
    "\n",
    "\n",
    "def get_weighted_masked_cross_entropy_loss(column_weight_maps):\n",
    "    \"\"\"\n",
    "    Creates a loss function that computes a weighted cross entropy loss, taking into account class imbalances.\n",
    "    :param column_weight_maps: Dictionary mapping column names to their corresponding class weight maps.\n",
    "    \"\"\"\n",
    "    def weighted_masked_cross_entropy_loss(y_pred, y_true):\n",
    "        # weighted_losses = torch.Tensor().to(device)\n",
    "        weighted_losses = []\n",
    "        col_weight_map = column_weight_maps\n",
    "        # print(col_weight_map)\n",
    "        mean_weight = np.mean(list(col_weight_map.values())) # just in case if a number is not recognised and the loss doesn't go crazy\n",
    "\n",
    "        # print(y_pred.size())\n",
    "        # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        weights_col = [col_weight_map.get(y.item(), mean_weight) for y in y_true]\n",
    "        # print(weights_col)\n",
    "        # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        loss_fn = F.cross_entropy\n",
    "        col_loss = loss_fn(y_pred, y_true, reduction = 'none').to(device)\n",
    "        \n",
    "        # loss_fn = nn.CrossEntropyLoss(reduction = 'none')\n",
    "        # col_loss = loss_fn(y_pred, y_true)\n",
    "        # print(y_true.dtype)\n",
    "        # print(col_loss)\n",
    "        weights_col = torch.Tensor(weights_col).to(device)\n",
    "        # print(weights_col)\n",
    "        # print(col_loss)\n",
    "        weighted_col_loss = weights_col * col_loss\n",
    "        # print(weighted_col_loss)\n",
    "        weighted_losses.append(weighted_col_loss.mean())\n",
    "\n",
    "        total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        \n",
    "        # for i, column in enumerate(column_weight_maps.keys()):\n",
    "        #     col_weight_map = column_weight_maps[column]\n",
    "        #     print(y_pred.size())\n",
    "        #     # Assuming y_true is a tensor of class indices for each column and y_pred are the logits\n",
    "        #     weights_col = torch.tensor([col_weight_map[y.item()] for y in y_true[:, i]], dtype=torch.float32, device=y_true.device)\n",
    "        #     print(weights_col)\n",
    "        #     # CrossEntropyLoss expects class indices as y_true, and logits as y_pred\n",
    "        #     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        #     col_loss = loss_fn(y_pred[:, i,], y_true[:, i])\n",
    "            \n",
    "        #     weighted_col_loss = weights_col * col_loss\n",
    "        #     weighted_losses.append(weighted_col_loss.mean())\n",
    "        \n",
    "        # total_weighted_loss = torch.stack(weighted_losses).mean()\n",
    "        return total_weighted_loss\n",
    "\n",
    "    return weighted_masked_cross_entropy_loss\n",
    "\n",
    "# Also assuming `columns` is a list of your target column names corresponding to y_true and y_pred\n",
    "weighted_cross_entropy_loss_fn = get_weighted_masked_cross_entropy_loss(column_weight_maps['a'])\n",
    "# loss = weighted_cross_entropy_loss_fn(y_true_tensor, y_pred_logits, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN Model (same as before)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # First GCN layer with ReLU activation\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, optimizer, and loss function\n",
    "input_dim = train_features_tensor.shape[1]  # 38 features in the input\n",
    "hidden_dim = 64  # Arbitrary hidden layer size\n",
    "output_dim = 2  # Number of output classes, adjust this based on your problem\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = weighted_cross_entropy_loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, LayerNorm\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Input dropout\n",
    "        self.input_dropout = torch.nn.Dropout(p=self.dropout_rate)\n",
    "\n",
    "        # First GCN layer\n",
    "        self.convs.append(GCNConv(input_dim, hidden_dims[0]))\n",
    "        self.bns.append(BatchNorm(hidden_dims[0]))\n",
    "        \n",
    "        # Additional GCN layers\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            self.convs.append(GCNConv(hidden_dims[i], hidden_dims[i+1]))\n",
    "            self.bns.append(BatchNorm(hidden_dims[i+1]))\n",
    "        \n",
    "        # Fully connected layers with weight normalization\n",
    "        self.fc1 = Linear(hidden_dims[-1], hidden_dims[-1] // 2)\n",
    "        self.fc1 = weight_norm(self.fc1)\n",
    "        self.fc2 = Linear(hidden_dims[-1] // 2, output_dim)\n",
    "        self.fc2 = weight_norm(self.fc2)\n",
    "        \n",
    "        # Layer normalization for fully connected layers\n",
    "        self.layer_norm1 = LayerNorm(hidden_dims[-1] // 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Apply input dropout\n",
    "        x = self.input_dropout(x)\n",
    "\n",
    "        # Apply GCN layers with ReLU activation and BatchNorm\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = conv(x, edge_index)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new training without dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storageG1/lwang/miniconda3/envs/new-ml/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "  8%|▊         | 51/600 [00:07<01:32,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.26495450735092163, Train Acc: 0.5617818631783631, Val Loss: 0.23005788028240204, Val Acc: 0.5611660593440916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 101/600 [00:14<01:23,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Train Loss: 0.2569220960140228, Train Acc: 0.7873431147251193, Val Loss: 0.23149727284908295, Val Acc: 0.7886517438833941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 151/600 [00:22<01:10,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Train Loss: 0.25296059250831604, Train Acc: 0.7873431147251193, Val Loss: 0.23158195614814758, Val Acc: 0.7886517438833941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 201/600 [00:29<01:05,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Train Loss: 0.24962733685970306, Train Acc: 0.7873431147251193, Val Loss: 0.23156410455703735, Val Acc: 0.7886517438833941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 251/600 [00:36<00:53,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, Train Loss: 0.24783457815647125, Train Acc: 0.7873431147251193, Val Loss: 0.23148450255393982, Val Acc: 0.7902134305049453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 301/600 [00:44<01:02,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, Train Loss: 0.24439606070518494, Train Acc: 0.7896411525543574, Val Loss: 0.23117633163928986, Val Acc: 0.7870900572618428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 351/600 [00:51<00:38,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Train Loss: 0.24003395438194275, Train Acc: 0.7848683047551706, Val Loss: 0.22681182622909546, Val Acc: 0.7777199375325351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 401/600 [00:58<00:32,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, Train Loss: 0.23683030903339386, Train Acc: 0.7576453950857345, Val Loss: 0.21948331594467163, Val Acc: 0.7522123893805309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 451/600 [01:05<00:25,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, Train Loss: 0.23395821452140808, Train Acc: 0.7318366625419834, Val Loss: 0.21966317296028137, Val Acc: 0.7272254034357105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 501/600 [01:12<00:16,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Train Loss: 0.23264765739440918, Train Acc: 0.5909492663956161, Val Loss: 0.21984286606311798, Val Acc: 0.5747006767308693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 551/600 [01:20<00:08,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550, Train Loss: 0.22995121777057648, Train Acc: 0.6347887572918508, Val Loss: 0.21820476651191711, Val Acc: 0.6111400312337324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:27<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600, Train Loss: 0.22929468750953674, Train Acc: 0.6165812267986566, Val Loss: 0.21467390656471252, Val Acc: 0.6054138469547111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f713c39d520>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "# [Your data preparation code]\n",
    "# Assume you have prepared:\n",
    "# - train_features_tensor, train_labels_tensor, train_edge_index_tensor\n",
    "# - val_features_tensor, val_labels_tensor, val_edge_index_tensor\n",
    "# - test_features_tensor, test_labels_tensor, test_edge_index_tensor\n",
    "\n",
    "# Step 1: Create Data Objects\n",
    "train_data = Data(x=train_features_tensor, edge_index=train_edge_index_tensor, y=train_labels_tensor)\n",
    "val_data = Data(x=val_features_tensor, edge_index=val_edge_index_tensor, y=val_labels_tensor)\n",
    "test_data = Data(x=test_features_tensor, edge_index=test_edge_index_tensor, y=test_labels_tensor)\n",
    "\n",
    "# # Step 2: Define the Model\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.5):\n",
    "#         super(GCN, self).__init__()\n",
    "#         self.convs = torch.nn.ModuleList()\n",
    "#         self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "#         # Input layer\n",
    "#         self.convs.append(GCNConv(input_dim, hidden_dims[0]))\n",
    "#         self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dims[0]))\n",
    "\n",
    "#         # Hidden layers\n",
    "#         for i in range(len(hidden_dims) - 1):\n",
    "#             self.convs.append(GCNConv(hidden_dims[i], hidden_dims[i + 1]))\n",
    "#             self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dims[i + 1]))\n",
    "\n",
    "#         # Output layer\n",
    "#         self.fc = torch.nn.Linear(hidden_dims[-1], output_dim)\n",
    "#         self.dropout_rate = dropout_rate\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "\n",
    "#         for conv, bn in zip(self.convs, self.batch_norms):\n",
    "#             x = conv(x, edge_index)\n",
    "#             x = bn(x)\n",
    "#             x = F.relu(x)\n",
    "#             x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "input_dim = train_data.num_node_features\n",
    "hidden_dims = [128, 64, 64, 64, 32, 32]\n",
    "output_dim = len(torch.unique(train_data.y))\n",
    "dropout_rate = 0.7\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 600\n",
    "\n",
    "# Step 3: Prepare Training\n",
    "model = GCN(input_dim, hidden_dims, output_dim, dropout_rate)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# Define optimizer with weight decay\n",
    "weight_decay = 5e-4  # Adjust as needed\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = weighted_cross_entropy_loss_fn\n",
    "\n",
    "\n",
    "def l1_regularization(model, l1_lambda):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "    return l1_lambda * l1_norm\n",
    "\n",
    "# In your training function\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data)\n",
    "    loss = criterion(out, train_data.y)\n",
    "    # Add L1 regularization\n",
    "    l1_lambda = 1e-5  # Adjust as needed\n",
    "    l1_reg = l1_regularization(model, l1_lambda)\n",
    "    loss = loss + l1_reg\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct = (preds == data.y).sum().item()\n",
    "        acc = correct / data.num_nodes\n",
    "        loss = criterion(out, data.y)\n",
    "\n",
    "    return acc, loss.item()\n",
    "\n",
    "# Step 4: Train the Model\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    train_loss = train()\n",
    "    val_acc, val_loss = evaluate(val_data)\n",
    "    if epoch % 50 == 0:\n",
    "        train_acc = evaluate(train_data)\n",
    "        # val_acc, val_loss = evaluate(val_data)\n",
    "        # print(f'Epoch {epoch:03d}, TrainLoss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        print(f'Epoch {epoch}, Train Loss: {train_loss}, Train Acc: {train_acc[0]}, Val Loss: {val_loss}, Val Acc: {val_acc}')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "# Test the model    \n",
    "test_acc = evaluate(test_data)\n",
    "# print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in [1e-3]:\n",
    "    print('=== testing variables', _)\n",
    "    \n",
    "    # lr = 1e-3 #0.8044\n",
    "    # input_dim = train_features_tensor.shape[1]  # 38 features in the input\n",
    "    # hidden_dim = [128, 64, 32]  # Arbitrary hidden layer size\n",
    "    # output_dim = 2  # Number of output classes, adjust this based on your problem\n",
    "    # Hyperparameters\n",
    "    input_dim = train_data.num_node_features\n",
    "    hidden_dims = [64, 32]\n",
    "    output_dim = len(torch.unique(train_data.y))\n",
    "    dropout_rate = 0.5\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 5e-4\n",
    "    num_epochs = 100\n",
    "    \n",
    "\n",
    "    model = GCN(input_dim, hidden_dim, output_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # criterion = torch.nn.CrossEntropyLoss()\n",
    "    criterion = weighted_cross_entropy_loss_fn\n",
    "    num_epochs = 300\n",
    "    \n",
    "    # Step 4: Train the Model\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = train()\n",
    "        if epoch % 10 == 0:\n",
    "            train_acc = evaluate(train_data)\n",
    "            val_acc = evaluate(val_data)\n",
    "            print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Test the model\n",
    "    test_acc = evaluate(test_data)\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old training with dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the training function\n",
    "def train(model, optimizer, criterion, train_loader):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0  # Track total loss for the epoch\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        out = model(batch)  # Forward pass\n",
    "        batch_y = batch.y.squeeze()\n",
    "        loss = criterion(out, batch_y)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        total_loss += loss.item()  # Accumulate the batch loss\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)  # Average loss for the epoch\n",
    "    # print(f'Training Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "# Define the validation function\n",
    "def validate(model, criterion, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for batch in val_loader:\n",
    "            out = model(batch)  # Forward pass\n",
    "            batch_y = batch.y.squeeze()\n",
    "            loss = criterion(out, batch_y)  # Compute loss\n",
    "            total_loss += loss.item()  # Accumulate the batch loss\n",
    "            \n",
    "            pred = out.argmax(dim=1)  # Get predictions\n",
    "            correct += (pred == batch.y).sum().item()  # Count correct predictions\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())  # Store predictions\n",
    "            all_labels.extend(batch.y.cpu().numpy())  # Store true labels\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)  # Compute accuracy\n",
    "    avg_loss = total_loss / len(val_loader)  # Average loss for the epoch\n",
    "    # print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch in test_loader:\n",
    "            out = model(batch)  # Forward pass\n",
    "            pred = out.argmax(dim=1)  # Get the predicted class (highest score)\n",
    "            all_preds.extend(pred.cpu().numpy())  # Store predictions\n",
    "            all_labels.extend(batch.y.cpu().numpy())  # Store true labels\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    sensitivity = recall_score(all_labels, all_preds)  # Same as recall\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    \n",
    "    # Output results\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, conf_matrix\n",
    "\n",
    "# Combine training and validation in the epoch loop\n",
    "def train_and_validate(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs=100):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        \n",
    "        # Training step\n",
    "        train_loss = train(model, optimizer, criterion, train_loader)\n",
    "        \n",
    "        # Validation step\n",
    "        val_loss, val_accuracy = validate(model, criterion, val_loader)\n",
    "\n",
    "        # Store losses and accuracy\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        if epoch %  100 == 0:\n",
    "            print(f'Epoch {epoch + 1} completed. Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\\n')\n",
    "            # print(f'Epoch {epoch + 1} completed. Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy * 100:.2f}%\\n')\n",
    "\n",
    "    # Plotting the loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    test(model, test_loader)\n",
    "    # Optionally, you can also plot validation accuracy\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='green')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Accuracy')\n",
    "    # plt.title('Validation Accuracy')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== testing variables 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m criterion \u001b[38;5;241m=\u001b[39m weighted_cross_entropy_loss_fn\n\u001b[1;32m     19\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 96\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m val_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# print(f'Epoch {epoch + 1}/{num_epochs}')\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# Validation step\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m validate(model, criterion, val_loader)\n",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[1;32m      7\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Track total loss for the epoch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reset gradients\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/new-ml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/new-ml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/new-ml/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/new-ml/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/storageG1/lwang/miniconda3/envs/new-ml/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    238\u001b[0m             ]\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for _ in [1e-3]:\n",
    "    print('=== testing variables', _)\n",
    "    \n",
    "    lr = 1e-3 #0.8044\n",
    "    input_dim = train_features_tensor.shape[1]  # 38 features in the input\n",
    "    hidden_dim = [128, 64, 32]  # Arbitrary hidden layer size\n",
    "    output_dim = 2  # Number of output classes, adjust this based on your problem\n",
    "\n",
    "    model = GCN(input_dim, hidden_dim, output_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # criterion = torch.nn.CrossEntropyLoss()\n",
    "    criterion = weighted_cross_entropy_loss_fn\n",
    "    num_epochs = 300\n",
    "\n",
    "    train_and_validate(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume clinical_lung_features is your input DataFrame and adjacency_matrix is your edge matrix\n",
    "features = clinical_lung_features.values  # shape (10150, 38)\n",
    "adjacency_matrix = adjacency_matrix  # shape (10150, 10150)\n",
    "\n",
    "# Assume y is your labels column in the dataframe\n",
    "y = clinical_lung_labels  # Replace this with your actual labels (shape: 10150,)\n",
    "\n",
    "# Step 1: Perform stratified split into train+val and test sets\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    np.arange(features.shape[0]),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Ensure that the split is stratified based on the labels\n",
    ")\n",
    "\n",
    "# Step 2: Further split the train+val set into separate training and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices,\n",
    "    test_size=0.25,  # 25% of train+val becomes the validation set, so 0.25 * 0.8 = 0.2 of the total data\n",
    "    random_state=42,\n",
    "    stratify=y.iloc[train_val_indices]  # Stratify based on the labels in the train+val set\n",
    ")\n",
    "\n",
    "# Separate features and labels based on the indices\n",
    "train_features = torch.tensor(features[train_indices], dtype=torch.float32)\n",
    "train_labels = torch.tensor(y.iloc[train_indices].values, dtype=torch.long)\n",
    "unique_rows, indices, counts = np.unique(train_features, axis=0, return_index=True, return_counts=True)\n",
    "train_features = train_features[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "\n",
    "\n",
    "val_features = torch.tensor(features[val_indices], dtype=torch.float32)\n",
    "val_labels = torch.tensor(y.iloc[val_indices].values, dtype=torch.long)\n",
    "unique_rows, indices, counts = np.unique(train_features, axis=0, return_index=True, return_counts=True)\n",
    "train_features = train_features[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "\n",
    "\n",
    "test_features = torch.tensor(features[test_indices], dtype=torch.float32)\n",
    "test_labels = torch.tensor(y.iloc[test_indices].values, dtype=torch.long)\n",
    "unique_rows, indices, counts = np.unique(train_features, axis=0, return_index=True, return_counts=True)\n",
    "train_features = train_features[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "\n",
    "# Train labels, validation labels, and test labels  \n",
    "\n",
    "# # Train adjacency matrix (rows and columns of the train_indices)\n",
    "# train_adj_matrix = adjacency_matrix[np.ix_(train_indices, train_indices)]\n",
    "\n",
    "# # Validation adjacency matrix (rows and columns of the val_indices)\n",
    "# val_adj_matrix = adjacency_matrix[np.ix_(val_indices, val_indices)]\n",
    "\n",
    "# # Test adjacency matrix (rows and columns of the test_indices)\n",
    "# test_adj_matrix = adjacency_matrix[np.ix_(test_indices, test_indices)]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume clinical_lung_features is your input DataFrame and adjacency_matrix is your edge matrix\n",
    "features = clinical_lung_features.values  # shape (10150, 38)\n",
    "adjacency_matrix = adjacency_matrix  # shape (10150, 10150)\n",
    "\n",
    "# Assume y is your labels column in the dataframe\n",
    "y = clinical_lung_labels  # Replace this with your actual labels (shape: 10150,)\n",
    "\n",
    "# Step 1: Perform stratified split into train+val and test sets\n",
    "train_val_indices, test_indices = train_test_split(\n",
    "    np.arange(features.shape[0]),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Ensure that the split is stratified based on the labels\n",
    ")\n",
    "\n",
    "# Step 2: Further split the train+val set into separate training and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_val_indices,\n",
    "    test_size=0.25,  # 25% of train+val becomes the validation set, so 0.25 * 0.8 = 0.2 of the total data\n",
    "    random_state=42,\n",
    "    stratify=y.iloc[train_val_indices]  # Stratify based on the labels in the train+val set\n",
    ")\n",
    "\n",
    "# Separate features and labels based on the indices\n",
    "train_features = torch.tensor(features[train_indices], dtype=torch.float32)\n",
    "val_features = torch.tensor(features[val_indices], dtype=torch.float32)\n",
    "test_features = torch.tensor(features[test_indices], dtype=torch.float32)\n",
    "\n",
    "train_labels = torch.tensor(y.iloc[train_indices].values, dtype=torch.float16)\n",
    "val_labels = torch.tensor(y.iloc[val_indices].values, dtype=torch.float16)\n",
    "test_labels = torch.tensor(y.iloc[test_indices].values, dtype=torch.float16)\n",
    "\n",
    "# Train adjacency matrix (rows and columns of the train_indices\n",
    "# Train, val, and test indices (these would be your node splits)\n",
    "train_indices = train_indices\n",
    "val_indices = val_indices\n",
    "test_indices = test_indices\n",
    "\n",
    "# Step 1: Create sets of indices for quick lookup\n",
    "train_set = set(train_indices)\n",
    "val_set = set(val_indices)\n",
    "test_set = set(test_indices)\n",
    "\n",
    "# Step 2: Function to filter edges for specific index set\n",
    "def filter_edges_by_node_split(edge_index, node_set):\n",
    "    mask = [(src in node_set) and (dst in node_set) for src, dst in zip(edge_index[0], edge_index[1])]\n",
    "    filtered_edge_index = edge_index[:, mask]\n",
    "    return filtered_edge_index\n",
    "\n",
    "# Step 3: Filter edges for train, validation, and test\n",
    "train_edge_index = filter_edges_by_node_split(edge_index_tensor, train_indices)\n",
    "val_edge_index = filter_edges_by_node_split(edge_index_tensor, val_indices)\n",
    "test_edge_index = filter_edges_by_node_split(edge_index_tensor, test_indices)\n",
    "\n",
    "# Now you can use these for respective splits\n",
    "print(\"Train Edge Index:\", train_edge_index)\n",
    "print(\"Validation Edge Index:\", val_edge_index)\n",
    "print(\"Test Edge Index:\", test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader, loader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume clinical_lung_features is your input DataFrame and adjacency_matrix is your edge matrix\n",
    "\n",
    "# Step 1: Convert DataFrame (features) and adjacency matrix into PyTorch tensors\n",
    "features = torch.tensor(clinical_lung_features.values, dtype=torch.float32)  # shape (10150, 38)\n",
    "adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)  # shape (10150, 10150)\n",
    "\n",
    "# Create edge_index from adjacency matrix\n",
    "def adjacency_to_edge_index(adj_matrix):\n",
    "    edge_index = []\n",
    "    for i in range(adj_matrix.shape[0]):\n",
    "        for j in range(adj_matrix.shape[1]):\n",
    "            if adj_matrix[i, j] != 0:  # If there's an edge\n",
    "                edge_index.append([i, j])\n",
    "    return torch.tensor(edge_index).t().contiguous()  # Transpose to match PyG's format\n",
    "\n",
    "edge_index = adjacency_to_edge_index(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Create a PyTorch Geometric Data object\n",
    "data = Data(x=features, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Create a DataLoader for batching\n",
    "batch_size = 64  # You can adjust this as needed\n",
    "loader = DataLoader([data], batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # First GCN layer with ReLU activation\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Instantiate the model, loss function, and optimizer\n",
    "input_dim = features.shape[1]  # 38 features in the input\n",
    "hidden_dim = 64  # Arbitrary hidden layer size, adjust as needed\n",
    "output_dim = 2  # Number of output classes, adjust based on your problem\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 6: Training Loop\n",
    "def train():\n",
    "    model.train()\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        # Assume you have labels (use the appropriate labels here)\n",
    "        loss = criterion(out, batch.y)  # You need to provide actual labels for batch.y\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Training loss: {loss.item()}\")\n",
    "\n",
    "# To run the training function\n",
    "train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
